{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f15748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current project path:  D:\\Data Repositories\\Coughvid\n"
     ]
    }
   ],
   "source": [
    "#set project path from config.yaml\n",
    "import pathlib\n",
    "import yaml\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "   config = yaml.safe_load(f)\n",
    "\n",
    "project_root = pathlib.Path(config[\"project\"][\"root_path\"])\n",
    "\n",
    "print(\"Current project path: \", project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4042a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_wav_dir = project_root / \"audio_wav_fulldset\"\n",
    "labels_dir = project_root / \"labels_json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed256c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda\\envs\\coughvid\\Lib\\site-packages\\pyAudioAnalysis\\..\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "#custom feature extraction function using pyaudioanalysis\n",
    "import numpy as np\n",
    "from pyAudioAnalysis import MidTermFeatures\n",
    "from pyAudioAnalysis import audioBasicIO\n",
    "\n",
    "def extract_features(Fs, x):\n",
    "\n",
    "    if x.size == 0:\n",
    "        return None \n",
    "\n",
    "    #standardization based on sampling rate\n",
    "    #1 sec mid length and 50ms short length as a safe bet when it comes to steps\n",
    "\n",
    "    mid_window = int(1.0 * Fs)\n",
    "    mid_step = int(1.0 * Fs)\n",
    "    short_window = int(0.05 * Fs)\n",
    "    short_step = int(0.05 * Fs)\n",
    "\n",
    "\n",
    "    mt_f, st_f, mt_names = MidTermFeatures.mid_feature_extraction(\n",
    "        x, Fs, mid_window, mid_step, short_window, short_step\n",
    "    )\n",
    "\n",
    "    #68 rows total, 34 means of the features as described in the docs and the other 34 are STDs\n",
    "        #only using means for now\n",
    "    feature_vector = np.mean(mt_f[:34, :], axis=1)\n",
    "\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31be00eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVMs cannot be trained with on-the-fly augmentation since the dataframe has to be static\n",
    "    #to save on storage space, K augmented versions of every wav will be created and their features will be added to the final DF \n",
    "    #this way we have more control over the creation of the DF and we don't have to go back and manually recreate thousands of files \n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, AddBackgroundNoise\n",
    "\n",
    "def augment_audio(Fs, x):\n",
    "\n",
    "    augment = Compose([\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "    TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "    PitchShift(min_semitones=-2, max_semitones=2, p=0.5),\n",
    "    ]) \n",
    "\n",
    "    augmented_x = augment(samples=x, sample_rate=Fs)\n",
    "\n",
    "    return augmented_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da31eca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning labels for stratification...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# --- STEP 1: PRE-SCAN LABELS ---\n",
    "file_to_status = {}\n",
    "wav_files = list(dset_wav_dir.glob(\"*.wav\"))\n",
    "\n",
    "print(\"Scanning labels for stratification...\")\n",
    "for wav_path in wav_files:\n",
    "    label_path = labels_dir / f\"{wav_path.stem}.json\"\n",
    "    if label_path.exists():\n",
    "        with open(label_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            status = data.get('status')\n",
    "            if status in [\"healthy\", \"symptomatic\", \"COVID-19\"]:\n",
    "                file_to_status[wav_path.stem] = status\n",
    "\n",
    "# Convert to Series for easy splitting\n",
    "ids = list(file_to_status.keys())\n",
    "labels = [file_to_status[i] for i in ids]\n",
    "\n",
    "# --- STEP 2: STRATIFIED SPLIT ---\n",
    "# This ensures valid_ids has the same 96/2/0.8 ratio as the original population\n",
    "train_ids, valid_ids = train_test_split(\n",
    "    ids, test_size=0.20, stratify=labels, random_state=42\n",
    ")\n",
    "valid_ids_set = set(valid_ids) # faster lookup\n",
    "\n",
    "# --- STEP 3: CALCULATE TRAINING QUOTAS ---\n",
    "k = 3\n",
    "# Undersample training to 80% of the smallest class (COVID-19)\n",
    "# 1315 * 0.8 = 1052. Then apply augmentation factor k.\n",
    "samples_per_class = int(1315 * 0.8) * k \n",
    "\n",
    "train_rows = {label: [] for label in [\"healthy\", \"symptomatic\", \"COVID-19\"]}\n",
    "valid_rows = []\n",
    "\n",
    "stats = {\"total\": len(wav_files), \"valid_added\": 0, \"train_added\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdee5989",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Phase 1: Validation Set: 100%|██████████| 4133/4133 [07:39<00:00,  9.00it/s, Total Val=4133]\n"
     ]
    }
   ],
   "source": [
    "# --- PHASE 1: VALIDATION COLLECTION ---\n",
    "valid_rows = []\n",
    "stats[\"valid_added\"] = 0\n",
    "\n",
    "# Create a filtered list of wav paths that belong to validation\n",
    "valid_wav_paths = [p for p in wav_files if p.stem in valid_ids_set]\n",
    "\n",
    "v_pbar = tqdm(valid_wav_paths, desc=\"Phase 1: Validation Set\")\n",
    "for wav_path in v_pbar:\n",
    "    status_value = file_to_status[wav_path.stem]\n",
    "    \n",
    "    try:\n",
    "        [Fs, x] = audioBasicIO.read_audio_file(str(wav_path))\n",
    "        features = extract_features(Fs, x) \n",
    "        valid_rows.append(list(features) + [status_value])\n",
    "        stats[\"valid_added\"] += 1\n",
    "        \n",
    "        # Update progress with class counts for validation\n",
    "        v_pbar.set_postfix({\"Total Val\": stats[\"valid_added\"]})\n",
    "    except Exception as e:\n",
    "        print(f\"Error on {wav_path.stem}: {e}\")\n",
    "\n",
    "df_valid = pd.DataFrame(valid_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "692ba906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of             0         1         2         3         4         5         6   \\\n",
      "0     0.133642  0.002768  2.869909  0.309003  0.245174  1.881792  0.012808   \n",
      "1     0.056516  0.003085  3.055794  0.113271  0.066920  0.613245  0.110051   \n",
      "2     0.148417  0.024882  2.735781  0.244915  0.185135  1.123642  0.099260   \n",
      "3     0.240110  0.005646  2.957414  0.369249  0.276009  1.775163  0.009528   \n",
      "4     0.028960  0.000527  3.171525  0.068770  0.040655  0.364464  0.036303   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "4128  0.095542  0.002295  2.968932  0.161171  0.127174  0.725894  0.069822   \n",
      "4129  0.197306  0.000872  3.032930  0.311191  0.255449  1.814753  0.041129   \n",
      "4130  0.340376  0.035111  2.946380  0.398258  0.262767  2.126538  0.006993   \n",
      "4131  0.225084  0.001692  2.868786  0.343297  0.231645  1.718931  0.017871   \n",
      "4132  0.275063  0.021999  2.931340  0.328595  0.155308  1.408996  0.126350   \n",
      "\n",
      "            7          8         9   ...        25        26        27  \\\n",
      "0     0.408492 -37.052363  1.523755  ...  0.018839  0.016777  0.018911   \n",
      "1     0.153875 -82.245494  0.069555  ...  0.003746  0.001849  0.003786   \n",
      "2     0.269475 -45.686815  1.411024  ...  0.014645  0.018573  0.029001   \n",
      "3     0.521194 -40.933406  1.182845  ...  0.017377  0.006804  0.019881   \n",
      "4     0.098850 -88.219878  0.035232  ...  0.001638  0.001944  0.001638   \n",
      "...        ...        ...       ...  ...       ...       ...       ...   \n",
      "4128  0.176071 -64.877707  0.809003  ...  0.006338  0.009207  0.007964   \n",
      "4129  0.378000 -40.973365  1.564103  ...  0.036888  0.009642  0.052734   \n",
      "4130  0.579275 -35.983778  0.511903  ...  0.009646  0.006617  0.013280   \n",
      "4131  0.428742 -38.777593  0.905892  ...  0.017264  0.009494  0.015614   \n",
      "4132  0.460500 -57.893426 -0.579964  ...  0.003266  0.002173  0.018096   \n",
      "\n",
      "            28        29        30        31        32        33           34  \n",
      "0     0.003080  0.009004  0.016148  0.012809  0.005871  0.017485      healthy  \n",
      "1     0.001067  0.001808  0.002646  0.003425  0.001578  0.043482      healthy  \n",
      "2     0.002782  0.009911  0.012037  0.011485  0.004399  0.027758      healthy  \n",
      "3     0.002243  0.004167  0.019446  0.025148  0.005195  0.017794  symptomatic  \n",
      "4     0.001671  0.002121  0.001847  0.001359  0.000655  0.048079     COVID-19  \n",
      "...        ...       ...       ...       ...       ...       ...          ...  \n",
      "4128  0.001224  0.004252  0.008905  0.011723  0.002672  0.038884      healthy  \n",
      "4129  0.002505  0.006459  0.015267  0.010113  0.004631  0.021156      healthy  \n",
      "4130  0.003700  0.006772  0.011630  0.010479  0.006203  0.017778     COVID-19  \n",
      "4131  0.011649  0.014240  0.011870  0.008092  0.005451  0.017208      healthy  \n",
      "4132  0.002292  0.003157  0.002730  0.007242  0.001770  0.029107  symptomatic  \n",
      "\n",
      "[4133 rows x 35 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df_valid.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7afcf180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your categories and parameters at the top\n",
    "target_labels = [\"healthy\", \"symptomatic\", \"COVID-19\"]\n",
    "k = 3 \n",
    "\n",
    "\n",
    "augmentation = False\n",
    "\n",
    "# Calculate the quota for training (80% of the minority class 1315)\n",
    "# Multiplied by k because each file generates k augmented instances\n",
    "if(augmentation):\n",
    "    samples_per_class = int(1315 * 0.8) * k\n",
    "else:\n",
    "    samples_per_class = int(1315 * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62d94c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Phase 2: Training Set: 100%|█████████▉| 16486/16531 [06:53<00:01, 39.89it/s, H=1052, S=1052, C=1051] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All training quotas reached. Stopping.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    " # --- PHASE 2: TRAINING COLLECTION ---\n",
    "\n",
    "train_rows = {label: [] for label in target_labels}\n",
    "\n",
    "stats[\"train_added\"] = 0\n",
    "\n",
    "# Filter for files belonging to training\n",
    "train_wav_paths = [p for p in wav_files if p.stem in train_ids]\n",
    "random.shuffle(train_wav_paths) # Shuffle for random undersampling\n",
    "\n",
    "t_pbar = tqdm(train_wav_paths, desc=\"Phase 2: Training Set\")\n",
    "\n",
    "for wav_path in t_pbar:\n",
    "    # Check if ALL class quotas are met to exit early\n",
    "    current_counts = {l: len(rows) for l, rows in train_rows.items()}\n",
    "    if all(count >= samples_per_class for count in current_counts.values()):\n",
    "        print(\"\\nAll training quotas reached. Stopping.\")\n",
    "        break\n",
    "    # Update TQDM with current training balance\n",
    "    t_pbar.set_postfix({\n",
    "        \"H\": current_counts[\"healthy\"],\n",
    "        \"S\": current_counts[\"symptomatic\"],\n",
    "        \"C\": current_counts[\"COVID-19\"]\n",
    "    })\n",
    "\n",
    "    status_value = file_to_status[wav_path.stem]   \n",
    "    # Only process if this specific class still needs samples\n",
    "\n",
    "    if current_counts[status_value] < samples_per_class:\n",
    "\n",
    "        if(augmentation):\n",
    "            try:\n",
    "                [Fs, x] = audioBasicIO.read_audio_file(str(wav_path))\n",
    "                for i in range(k):\n",
    "                    if len(train_rows[status_value]) >= samples_per_class:\n",
    "                        break\n",
    "\n",
    "                    # Apply augmentation only to training\n",
    "                    x = augment_audio(Fs, x)\n",
    "                    features = extract_features(Fs, x)\n",
    "                    train_rows[status_value].append(list(features) + [status_value])\n",
    "                    stats[\"train_added\"] += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error on {wav_path.stem}: {e}\")\n",
    "        else:\n",
    "            try:\n",
    "                [Fs, x] = audioBasicIO.read_audio_file(str(wav_path))\n",
    "                features = extract_features(Fs, x)\n",
    "                train_rows[status_value].append(list(features) + [status_value])\n",
    "                stats[\"train_added\"] += 1   \n",
    "            except Exception as e:\n",
    "                print(f\"Error on {wav_path.stem}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# Flatten and create DataFrame\n",
    "all_train = [row for label_list in train_rows.values() for row in label_list]\n",
    "\n",
    "df_train = pd.DataFrame(all_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "504c7c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Value Counts:\n",
      "34\n",
      "healthy        3095\n",
      "symptomatic     775\n",
      "COVID-19        263\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value Counts:\n",
      "34\n",
      "healthy        1052\n",
      "symptomatic    1052\n",
      "COVID-19       1052\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nValue Counts:\")\n",
    "print(df_valid.iloc[:, -1].value_counts())\n",
    "\n",
    "print(\"\\nValue Counts:\")\n",
    "print(df_train.iloc[:, -1].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07caae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"train_df.csv\", index = False)\n",
    "df_valid.to_csv(\"valid_df.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fc1f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coughvid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
