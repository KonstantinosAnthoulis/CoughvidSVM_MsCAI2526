{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f15748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current project path:  D:\\Data Repositories\\Coughvid\n"
     ]
    }
   ],
   "source": [
    "#set project path from config.yaml\n",
    "import pathlib\n",
    "import yaml\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "   config = yaml.safe_load(f)\n",
    "\n",
    "project_root = pathlib.Path(config[\"project\"][\"root_path\"])\n",
    "\n",
    "print(\"Current project path: \", project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4042a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_wav_dir = project_root / \"audio_wav_fulldset\"\n",
    "labels_dir = project_root / \"labels_json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed256c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda\\envs\\coughvid\\Lib\\site-packages\\pyAudioAnalysis\\..\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "#custom feature extraction function using pyaudioanalysis\n",
    "import numpy as np\n",
    "from pyAudioAnalysis import MidTermFeatures\n",
    "from pyAudioAnalysis import audioBasicIO\n",
    "\n",
    "def extract_features(Fs, x):\n",
    "\n",
    "    if x.size == 0:\n",
    "        return None \n",
    "\n",
    "    #standardization based on sampling rate\n",
    "    #1 sec mid length and 50ms short length as a safe bet when it comes to steps\n",
    "\n",
    "    mid_window = int(1.0 * Fs)\n",
    "    mid_step = int(1.0 * Fs)\n",
    "    short_window = int(0.05 * Fs)\n",
    "    short_step = int(0.05 * Fs)\n",
    "\n",
    "\n",
    "    mt_f, st_f, mt_names = MidTermFeatures.mid_feature_extraction(\n",
    "        x, Fs, mid_window, mid_step, short_window, short_step\n",
    "    )\n",
    "\n",
    "    #68 rows total, 34 means of the features as described in the docs and the other 34 are STDs\n",
    "        #only using means for now\n",
    "    feature_vector = np.mean(mt_f[:34, :], axis=1)\n",
    "\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31be00eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVMs cannot be trained with on-the-fly augmentation since the dataframe has to be static\n",
    "    #to save on storage space, K augmented versions of every wav will be created and their features will be added to the final DF \n",
    "    #this way we have more control over the creation of the DF and we don't have to go back and manually recreate thousands of files \n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, AddBackgroundNoise\n",
    "\n",
    "def augment_audio(Fs, x):\n",
    "\n",
    "    augment = Compose([\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "    TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "    PitchShift(min_semitones=-2, max_semitones=2, p=0.5),\n",
    "    ]) #reproducibility\n",
    "\n",
    "    augmented_x = augment(samples=x, sample_rate=Fs)\n",
    "\n",
    "    return augmented_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d94c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating training DF:   0%|          | 56/20664 [00:07<48:08,  7.13it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     66\u001b[39m augmented_x = augment_audio(Fs, x)\n\u001b[32m     68\u001b[39m \u001b[38;5;66;03m#call the custom function for mid extraction\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m pyaudio_features = \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugmented_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# create the final df row w status \u001b[39;00m\n\u001b[32m     72\u001b[39m new_row = \u001b[38;5;28mlist\u001b[39m(pyaudio_features) + [status_value]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36mextract_features\u001b[39m\u001b[34m(Fs, x)\u001b[39m\n\u001b[32m     16\u001b[39m short_window = \u001b[38;5;28mint\u001b[39m(\u001b[32m0.05\u001b[39m * Fs)\n\u001b[32m     17\u001b[39m short_step = \u001b[38;5;28mint\u001b[39m(\u001b[32m0.05\u001b[39m * Fs)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m mt_f, st_f, mt_names = \u001b[43mMidTermFeatures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmid_feature_extraction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mFs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmid_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmid_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshort_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshort_step\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;66;03m#68 rows total, 34 means of the features as described in the docs and the other 34 are STDs\u001b[39;00m\n\u001b[32m     25\u001b[39m     \u001b[38;5;66;03m#only using means for now\u001b[39;00m\n\u001b[32m     26\u001b[39m feature_vector = np.mean(mt_f[:\u001b[32m34\u001b[39m, :], axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\Anaconda\\envs\\coughvid\\Lib\\site-packages\\pyAudioAnalysis\\MidTermFeatures.py:123\u001b[39m, in \u001b[36mmid_feature_extraction\u001b[39m\u001b[34m(signal, sampling_rate, mid_window, mid_step, short_window, short_step)\u001b[39m\n\u001b[32m    120\u001b[39m         cur_st_feats = short_features[i][cur_position:end]\n\u001b[32m    122\u001b[39m         mid_features[i].append(np.mean(cur_st_feats))\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m         mid_features[i + n_feats].append(\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur_st_feats\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    124\u001b[39m         cur_position += mt_step_ratio\n\u001b[32m    125\u001b[39m mid_features = np.array(mid_features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\Anaconda\\envs\\coughvid\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:4064\u001b[39m, in \u001b[36mstd\u001b[39m\u001b[34m(a, axis, dtype, out, ddof, keepdims, where, mean, correction)\u001b[39m\n\u001b[32m   4061\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4062\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m std(axis=axis, dtype=dtype, out=out, ddof=ddof, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m4064\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_std\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mddof\u001b[49m\u001b[43m=\u001b[49m\u001b[43mddof\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4065\u001b[39m \u001b[43m                     \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\Anaconda\\envs\\coughvid\\Lib\\site-packages\\numpy\\_core\\_methods.py:222\u001b[39m, in \u001b[36m_std\u001b[39m\u001b[34m(a, axis, dtype, out, ddof, keepdims, where, mean)\u001b[39m\n\u001b[32m    220\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_std\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, ddof=\u001b[32m0\u001b[39m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m, *,\n\u001b[32m    221\u001b[39m          where=\u001b[38;5;28;01mTrue\u001b[39;00m, mean=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     ret = \u001b[43m_var\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mddof\u001b[49m\u001b[43m=\u001b[49m\u001b[43mddof\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m               \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwhere\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    225\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu.ndarray):\n\u001b[32m    226\u001b[39m         ret = um.sqrt(ret, out=ret)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Software\\Anaconda\\envs\\coughvid\\Lib\\site-packages\\numpy\\_core\\_methods.py:150\u001b[39m, in \u001b[36m_var\u001b[39m\u001b[34m(a, axis, dtype, out, ddof, keepdims, where, mean)\u001b[39m\n\u001b[32m    146\u001b[39m         ret = ret / rcount\n\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_var\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, ddof=\u001b[32m0\u001b[39m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m, *,\n\u001b[32m    151\u001b[39m          where=\u001b[38;5;28;01mTrue\u001b[39;00m, mean=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    152\u001b[39m     arr = asanyarray(a)\n\u001b[32m    154\u001b[39m     rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "k = 1 #number of augmented instances created per wav file\n",
    "\n",
    "target_labels = [\"healthy\", \"symptomatic\", \"COVID-19\"]\n",
    "samples_per_class = 50 * k #1315 is the number of COVID-19 instances in the dataset and the lowest class number. \n",
    "    #to ensure class balance we are undersampling to the number of COVID instances\n",
    "\n",
    "class_rows = {label: [] for label in target_labels}\n",
    "\n",
    "#counting missing skipped etc\n",
    "stats = {\n",
    "    \"total_wavs_found\": 0,\n",
    "    \"missing_json\": 0,\n",
    "    \"empty_status\": 0,\n",
    "    \"valid_extracted\": 0,\n",
    "    \"class_full_skip\": 0\n",
    "}\n",
    "\n",
    "wav_files = list(dset_wav_dir.glob(\"*.wav\"))\n",
    "random.shuffle(wav_files) \n",
    "\n",
    "stats[\"total_wavs_found\"] = len(wav_files)\n",
    "\n",
    "for wav_path in tqdm(wav_files, desc=\"Creating training DF\"):\n",
    "        # Calculate total collected so far across all classes\n",
    "    current_total = sum(len(rows) for rows in class_rows.values())\n",
    "\n",
    "    if current_total >= 3 * samples_per_class:\n",
    "        break\n",
    "        \n",
    "    file_id = wav_path.stem\n",
    "\n",
    "    label_path = labels_dir / f\"{file_id}.json\"\n",
    "    \n",
    "    if not label_path.exists():\n",
    "        stats[\"missing_json\"] += 1\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        with open(label_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        status_value = data.get('status')\n",
    "        \n",
    "        # if no assigned status (happens in a lot of cases, skip entry and move to next)\n",
    "        # or if the status is not in our target balanced list\n",
    "        if status_value not in target_labels:\n",
    "            stats[\"empty_status\"] += 1\n",
    "            continue\n",
    "            \n",
    "        # Check if we already have enough for this specific class\n",
    "        if len(class_rows[status_value]) >= samples_per_class:\n",
    "            stats[\"class_full_skip\"] += 1\n",
    "            continue\n",
    "        #read the audio file\n",
    "        [Fs, x] = audioBasicIO.read_audio_file(str(wav_path))\n",
    "        \n",
    "        #augment the audio file\n",
    "        augmented_x = augment_audio(Fs, x)\n",
    "\n",
    "        #call the custom function for mid extraction\n",
    "        pyaudio_features = extract_features(Fs, augmented_x)\n",
    "        \n",
    "        # create the final df row w status \n",
    "        new_row = list(pyaudio_features) + [status_value]\n",
    "        class_rows[status_value].append(new_row)\n",
    "        stats[\"valid_extracted\"] += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_id}: {e}\")\n",
    "\n",
    "# Flatten the dictionary of lists into the final all_rows list\n",
    "for label in target_labels:\n",
    "    all_rows.extend(class_rows[label])\n",
    "\n",
    "# Final Summary\n",
    "print(\"\\n--- Processing Summary ---\")\n",
    "print(f\"Total .wav files scanned: {stats['total_wavs_found']}\")\n",
    "print(f\"Files skipped (JSON missing): {stats['missing_json']}\")\n",
    "print(f\"Files skipped (Status empty/invalid): {stats['empty_status']}\")\n",
    "print(f\"Files skipped (Class quota reached): {stats['class_full_skip']}\")\n",
    "print(f\"Successfully added to DF: {len(all_rows)}\")\n",
    "\n",
    "# Breakdown of final counts\n",
    "for label in target_labels:\n",
    "    print(f\" - {label}: {len(class_rows[label])} samples\")\n",
    "\n",
    "final_df = pd.DataFrame(all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504c7c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Status Values:\n",
      "['healthy' 'symptomatic' 'COVID-19']\n",
      "\n",
      "Value Counts:\n",
      "34\n",
      "healthy        1315\n",
      "symptomatic    1315\n",
      "COVID-19       1315\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Show unique values\n",
    "print(\"Unique Status Values:\")\n",
    "print(final_df.iloc[:, -1].unique())\n",
    "\n",
    "# Better yet, show the count of each to check for class imbalance\n",
    "print(\"\\nValue Counts:\")\n",
    "print(final_df.iloc[:, -1].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07caae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"toy_dset.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coughvid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
