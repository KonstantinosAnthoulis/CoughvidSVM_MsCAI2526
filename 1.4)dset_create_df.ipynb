{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f15748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current project path:  D:\\Data Repositories\\Coughvid\n"
     ]
    }
   ],
   "source": [
    "#set project path from config.yaml\n",
    "import pathlib\n",
    "import yaml\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "   config = yaml.safe_load(f)\n",
    "\n",
    "project_root = pathlib.Path(config[\"project\"][\"root_path\"])\n",
    "\n",
    "print(\"Current project path: \", project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4042a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_wav_dir = project_root / \"audio_wav_fulldset\"\n",
    "labels_dir = project_root / \"labels_json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed256c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Software\\Anaconda\\envs\\coughvid\\Lib\\site-packages\\pyAudioAnalysis\\..\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "#custom feature extraction function using pyaudioanalysis\n",
    "import numpy as np\n",
    "from pyAudioAnalysis import MidTermFeatures\n",
    "from pyAudioAnalysis import audioBasicIO\n",
    "\n",
    "def extract_features(Fs, x):\n",
    "\n",
    "    if x.size == 0:\n",
    "        return None \n",
    "\n",
    "    #standardization based on sampling rate\n",
    "    #1 sec mid length and 50ms short length as a safe bet when it comes to steps\n",
    "\n",
    "    mid_window = int(1.0 * Fs)\n",
    "    mid_step = int(1.0 * Fs)\n",
    "    short_window = int(0.05 * Fs)\n",
    "    short_step = int(0.05 * Fs)\n",
    "\n",
    "\n",
    "    mt_f, st_f, mt_names = MidTermFeatures.mid_feature_extraction(\n",
    "        x, Fs, mid_window, mid_step, short_window, short_step\n",
    "    )\n",
    "\n",
    "    #68 rows total, 34 means of the features as described in the docs and the other 34 are STDs\n",
    "        #only using means for now\n",
    "    feature_vector = np.mean(mt_f[:34, :], axis=1)\n",
    "\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31be00eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVMs cannot be trained with on-the-fly augmentation since the dataframe has to be static\n",
    "    #to save on storage space, K augmented versions of every wav will be created and their features will be added to the final DF \n",
    "    #this way we have more control over the creation of the DF and we don't have to go back and manually recreate thousands of files \n",
    "from audiomentations import Compose, AddGaussianNoise, TimeStretch, PitchShift, AddBackgroundNoise\n",
    "\n",
    "def augment_audio(Fs, x):\n",
    "\n",
    "    augment = Compose([\n",
    "    AddGaussianNoise(min_amplitude=0.001, max_amplitude=0.015, p=0.5),\n",
    "    TimeStretch(min_rate=0.8, max_rate=1.25, p=0.5),\n",
    "    PitchShift(min_semitones=-2, max_semitones=2, p=0.5),\n",
    "    ]) #reproducibility\n",
    "\n",
    "    augmented_x = augment(samples=x, sample_rate=Fs)\n",
    "\n",
    "    return augmented_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62d94c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating training DF: 100%|█████████▉| 20660/20664 [29:44<00:00, 11.58it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Summary ---\n",
      "Total .wav files scanned: 20664\n",
      "Files skipped (JSON missing): 0\n",
      "Files skipped (Status empty/invalid): 0\n",
      "Files skipped (Class quota reached): 16715\n",
      "Successfully added to DF: 11835\n",
      " - healthy: 3945 samples\n",
      " - symptomatic: 3945 samples\n",
      " - COVID-19: 3945 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "all_rows = []\n",
    "\n",
    "k = 3 #number of augmented instances created per wav file\n",
    "\n",
    "target_labels = [\"healthy\", \"symptomatic\", \"COVID-19\"]\n",
    "samples_per_class = 1315 * k #1315 is the number of COVID-19 instances in the dataset and the lowest class number. \n",
    "    #to ensure class balance we are undersampling to the number of COVID instances\n",
    "\n",
    "class_rows = {label: [] for label in target_labels}\n",
    "\n",
    "#counting missing skipped etc\n",
    "stats = {\n",
    "    \"total_wavs_found\": 0,\n",
    "    \"missing_json\": 0,\n",
    "    \"empty_status\": 0,\n",
    "    \"valid_extracted\": 0,\n",
    "    \"class_full_skip\": 0\n",
    "}\n",
    "\n",
    "wav_files = list(dset_wav_dir.glob(\"*.wav\"))\n",
    "random.shuffle(wav_files) \n",
    "\n",
    "stats[\"total_wavs_found\"] = len(wav_files)\n",
    "\n",
    "for wav_path in tqdm(wav_files, desc=\"Creating training DF\"):\n",
    "        # Calculate total collected so far across all classes\n",
    "    current_total = sum(len(rows) for rows in class_rows.values())\n",
    "\n",
    "    if current_total >= 3 * samples_per_class:\n",
    "        break\n",
    "        \n",
    "    file_id = wav_path.stem\n",
    "\n",
    "    label_path = labels_dir / f\"{file_id}.json\"\n",
    "    \n",
    "    if not label_path.exists():\n",
    "        stats[\"missing_json\"] += 1\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        with open(label_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        status_value = data.get('status')\n",
    "        \n",
    "        # if no assigned status (happens in a lot of cases, skip entry and move to next)\n",
    "        # or if the status is not in our target balanced list\n",
    "        if status_value not in target_labels:\n",
    "            stats[\"empty_status\"] += 1\n",
    "            continue\n",
    "            \n",
    "        # Check if we already have enough for this specific class\n",
    "        if len(class_rows[status_value]) >= samples_per_class:\n",
    "            stats[\"class_full_skip\"] += 1\n",
    "            continue\n",
    "        #read the audio file\n",
    "        [Fs, x] = audioBasicIO.read_audio_file(str(wav_path))\n",
    "        \n",
    "        for i in range(k):\n",
    "                    # Check quota again inside loop to prevent overfilling \n",
    "                    if len(class_rows[status_value]) >= samples_per_class:\n",
    "                        break\n",
    "\n",
    "                    #function introduces randomness each call\n",
    "                    augmented_x = augment_audio(Fs, x)\n",
    "\n",
    "                    #custom feature extraction\n",
    "                    pyaudio_features = extract_features(Fs, augmented_x)\n",
    "                    \n",
    "                    # Append to list with the same status_value\n",
    "                    new_row = list(pyaudio_features) + [status_value]\n",
    "                    class_rows[status_value].append(new_row)\n",
    "                    stats[\"valid_extracted\"] += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_id}: {e}\")\n",
    "\n",
    "# Flatten the dictionary of lists into the final all_rows list\n",
    "for label in target_labels:\n",
    "    all_rows.extend(class_rows[label])\n",
    "\n",
    "# Final Summary\n",
    "print(\"\\n--- Processing Summary ---\")\n",
    "print(f\"Total .wav files scanned: {stats['total_wavs_found']}\")\n",
    "print(f\"Files skipped (JSON missing): {stats['missing_json']}\")\n",
    "print(f\"Files skipped (Status empty/invalid): {stats['empty_status']}\")\n",
    "print(f\"Files skipped (Class quota reached): {stats['class_full_skip']}\")\n",
    "print(f\"Successfully added to DF: {len(all_rows)}\")\n",
    "\n",
    "# Breakdown of final counts\n",
    "for label in target_labels:\n",
    "    print(f\" - {label}: {len(class_rows[label])} samples\")\n",
    "\n",
    "final_df = pd.DataFrame(all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "504c7c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Status Values:\n",
      "['healthy' 'symptomatic' 'COVID-19']\n",
      "\n",
      "Value Counts:\n",
      "34\n",
      "healthy        3945\n",
      "symptomatic    3945\n",
      "COVID-19       3945\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Show unique values\n",
    "print(\"Unique Status Values:\")\n",
    "print(final_df.iloc[:, -1].unique())\n",
    "\n",
    "# Better yet, show the count of each to check for class imbalance\n",
    "print(\"\\nValue Counts:\")\n",
    "print(final_df.iloc[:, -1].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07caae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"dset_augmented.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b5e394",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coughvid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
