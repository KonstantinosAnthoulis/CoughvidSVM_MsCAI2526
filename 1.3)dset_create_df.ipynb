{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f15748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current project path:  C:\\Users\\Konstantinos\\Desktop\\Coughvid Data\n"
     ]
    }
   ],
   "source": [
    "#set project path from config.yaml\n",
    "import pathlib\n",
    "import yaml\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "   config = yaml.safe_load(f)\n",
    "\n",
    "project_root = pathlib.Path(config[\"project\"][\"root_path\"])\n",
    "\n",
    "print(\"Current project path: \", project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4042a5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_wav_dir = project_root / \"audio_wav_fulldset\"\n",
    "labels_dir = project_root / \"labels_json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed256c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyAudioAnalysis import MidTermFeatures\n",
    "from pyAudioAnalysis import audioBasicIO\n",
    "\n",
    "def extract_features(path):\n",
    "    [Fs, x] = audioBasicIO.read_audio_file(str(path))\n",
    "\n",
    "    if x.size == 0:\n",
    "        return None \n",
    "\n",
    "    # Standardization based on sampling rate\n",
    "    mid_window = int(1.0 * Fs)\n",
    "    mid_step = int(1.0 * Fs)\n",
    "    short_window = int(0.05 * Fs)\n",
    "    short_step = int(0.05 * Fs)\n",
    "\n",
    "    # mt_f shape is (136, n_windows)\n",
    "    # The first 68 rows are means and stds of the 34 short-term features\n",
    "    mt_f, st_f, mt_names = MidTermFeatures.mid_feature_extraction(\n",
    "        x, Fs, mid_window, mid_step, short_window, short_step\n",
    "    )\n",
    "\n",
    "    # 1. Slice the first 34 rows (the means of the short-term features)\n",
    "    # 2. Average across the columns (the mid-term windows) \n",
    "    # This results in a 1D array of 34 values\n",
    "    feature_vector = np.mean(mt_f[:34, :], axis=1)\n",
    "\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62d94c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating training DF:   0%|          | 167/34434 [00:18<1:04:57,  8.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing Summary ---\n",
      "Total .wav files scanned: 34434\n",
      "Files skipped (JSON missing): 0\n",
      "Files skipped (Status empty): 67\n",
      "Successfully added to DF: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "all_rows = []\n",
    "LIMIT = 100\n",
    "\n",
    "# Diagnostic Counters\n",
    "stats = {\n",
    "    \"total_wavs_found\": 0,\n",
    "    \"missing_json\": 0,\n",
    "    \"empty_status\": 0,\n",
    "    \"valid_extracted\": 0\n",
    "}\n",
    "\n",
    "wav_files = list(dset_wav_dir.glob(\"*.wav\"))\n",
    "stats[\"total_wavs_found\"] = len(wav_files)\n",
    "\n",
    "for wav_path in tqdm(wav_files, desc=\"Creating training DF\"):\n",
    "    if len(all_rows) >= LIMIT:\n",
    "        break\n",
    "        \n",
    "    file_id = wav_path.stem\n",
    "    # Changed extension to .json\n",
    "    label_path = labels_dir / f\"{file_id}.json\"\n",
    "    \n",
    "    # Check 1: Does JSON exist?\n",
    "    if not label_path.exists():\n",
    "        stats[\"missing_json\"] += 1\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        # Load JSON file\n",
    "        with open(label_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            \n",
    "        # Check 2: Get \"status\" from the dictionary\n",
    "        status_value = data.get('status')\n",
    "        \n",
    "        if status_value is None or str(status_value).strip() == \"\":\n",
    "            stats[\"empty_status\"] += 1\n",
    "            continue\n",
    "            \n",
    "        # 2. Success: Extract Features\n",
    "        pyaudio_features = extract_features(str(wav_path))\n",
    "        \n",
    "        # Combine features and status\n",
    "        new_row = list(pyaudio_features) + [status_value]\n",
    "        all_rows.append(new_row)\n",
    "        stats[\"valid_extracted\"] += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_id}: {e}\")\n",
    "\n",
    "# Final Summary\n",
    "print(\"\\n--- Processing Summary ---\")\n",
    "print(f\"Total .wav files scanned: {stats['total_wavs_found']}\")\n",
    "print(f\"Files skipped (JSON missing): {stats['missing_json']}\")\n",
    "print(f\"Files skipped (Status empty): {stats['empty_status']}\")\n",
    "print(f\"Successfully added to DF: {stats['valid_extracted']}\")\n",
    "\n",
    "final_df = pd.DataFrame(all_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504c7c55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Status Values:\n",
      "['healthy' 'COVID-19' 'symptomatic']\n",
      "\n",
      "Value Counts:\n",
      "34\n",
      "healthy        84\n",
      "symptomatic    12\n",
      "COVID-19        4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Show unique values\n",
    "print(\"Unique Status Values:\")\n",
    "print(final_df.iloc[:, -1].unique())\n",
    "\n",
    "# Better yet, show the count of each to check for class imbalance\n",
    "print(\"\\nValue Counts:\")\n",
    "print(final_df.iloc[:, -1].value_counts())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07caae31",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"toy_dset.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coughvid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
