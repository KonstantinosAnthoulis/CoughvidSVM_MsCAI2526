{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "704cdf65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current project path:  C:\\Users\\Konstantinos\\Desktop\\Coughvid Data\n"
     ]
    }
   ],
   "source": [
    "#set project path from config.yaml\n",
    "import pathlib\n",
    "import yaml\n",
    "\n",
    "with open(\"config.yaml\", \"r\") as f:\n",
    "   config = yaml.safe_load(f)\n",
    "\n",
    "project_root = pathlib.Path(config[\"project\"][\"root_path\"])\n",
    "\n",
    "print(\"Current project path: \", project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd6e41ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1XSY-5SFv_F2GEP9VZOTrPxE72N8aXYd6\n",
      "From (redirected): https://drive.google.com/uc?id=1XSY-5SFv_F2GEP9VZOTrPxE72N8aXYd6&confirm=t&uuid=b05493dc-fbdd-47d4-adb1-785b075194e0\n",
      "To: C:\\Users\\Konstantinos\\Desktop\\Coughvid Data\\dsetv3_backup\\dsetv3.zip\n",
      "100%|██████████| 2.30G/2.30G [04:15<00:00, 8.98MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Konstantinos\\\\Desktop\\\\Coughvid Data\\\\dsetv3_backup\\\\dsetv3.zip'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "#naming backup to keep the original dset zipped as a backup to avoid redownloading\n",
    "zipdl_dir = project_root / \"dsetv3_backup\"\n",
    "#automatically make path, avoiding having to create the files manually\n",
    "zipdl_dir.mkdir(parents=True, exist_ok=True) \n",
    "\n",
    "#NOTE anth: to remove any confusion with _dir and _path suffixes\n",
    "    #dir: goes to folder\n",
    "    #path: goes to file\n",
    "        #it's my way of separating what is what, hopefully it's not confusing for any future readers\n",
    "\n",
    "#from gdrive link, *DO NOT CHANGE*\n",
    "\n",
    "import gdown\n",
    "\n",
    "file_id = \"1XSY-5SFv_F2GEP9VZOTrPxE72N8aXYd6\"\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "zip_path = zipdl_dir / \"dsetv3.zip\"\n",
    "\n",
    "gdown.download(url, str(zip_path), quiet=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8387543e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Konstantinos\\Desktop\\Coughvid Data\\dsetv3_backup\\dsetv3.zip\n"
     ]
    }
   ],
   "source": [
    "#unzip the dset in a separate file \n",
    "    #NOTE unzipping will result in a single file with both .webm (audio) and label (.json) files dumped together\n",
    "    #will sort in separate directories to make life easier \n",
    "\n",
    "zip_path = zipdl_dir / \"dsetv3.zip\"\n",
    "\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "dset_extracted_dir = project_root / \"unzipped_dset\" #dump the entire zip here \n",
    "labels_dir = project_root / \"labels_json\"\n",
    "webm_dir = project_root / \"audio_webm\"\n",
    "ogg_dir = project_root / \"audio_ogg\"\n",
    "wav_dir = project_root / \"audio_wav\"\n",
    "\n",
    "#create directories\n",
    "dset_extracted_dir.mkdir(parents=True, exist_ok=True) \n",
    "labels_dir.mkdir(parents=True, exist_ok=True) \n",
    "webm_dir.mkdir(parents=True, exist_ok=True) \n",
    "ogg_dir.mkdir(parents = True, exist_ok= True)\n",
    "wav_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "print(zip_path)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(dset_extracted_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8dca030",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sorting files: 100%|██████████| 68869/68869 [00:35<00:00, 1914.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping unknown file type: metadata_compiled.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "#reecursively get all files in the extracted dataset directory\n",
    "    #there will only be one folder in dset_extracted_dir \n",
    "        #just doing it this way because the final folder name can have some variability due to how gdown names files \n",
    "all_files = [f for f in dset_extracted_dir.rglob(\"*\") if f.is_file()]\n",
    "\n",
    "for file_path in tqdm(all_files, desc=\"Sorting files\"):\n",
    "    suffix = file_path.suffix.lower()\n",
    "    if suffix == \".json\":\n",
    "        shutil.move(str(file_path), labels_dir / file_path.name)\n",
    "    elif suffix == \".webm\":\n",
    "        shutil.move(str(file_path), webm_dir / file_path.name)\n",
    "    elif suffix == \".ogg\":\n",
    "        shutil.move(str(file_path), ogg_dir / file_path.name)\n",
    "    elif suffix == \".wav\":\n",
    "        shutil.move(str(file_path), wav_dir / file_path.name)\n",
    "    else:\n",
    "        print(f\"Skipping unknown file type: {file_path.name}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coughvid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
